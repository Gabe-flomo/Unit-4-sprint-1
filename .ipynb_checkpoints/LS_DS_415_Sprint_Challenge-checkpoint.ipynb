{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Sprint Challenge\n",
    "## *Data Science Unit 4 Sprint 1*\n",
    "\n",
    "After a week of Natural Language Processing, you've learned some cool new stuff: how to process text, how turn text into vectors, and how to model topics from documents. Apply your newly acquired skills to one of the most famous NLP datasets out there: [Yelp](https://www.yelp.com/dataset/challenge). As part of the job selection process, some of my friends have been asked to create analysis of this dataset, so I want to empower you to have a head start.  \n",
    "\n",
    "The real dataset is massive (almost 8 gigs uncompressed). I've sampled the data for you to something more managable for the Sprint Challenge. You can analyze the full dataset as a stretch goal or after the sprint challenge. As you work on the challenge, I suggest adding notes about your findings and things you want to analyze in the future.\n",
    "\n",
    "## Challenge Objectives\n",
    "*Successfully complete these all these objectives to earn a 2. There are more details on each objective further down in the notebook.*\n",
    "* <a href=\"#p1\">Part 1</a>: Write a function to tokenize the yelp reviews\n",
    "* <a href=\"#p2\">Part 2</a>: Create a vector representation of those tokens\n",
    "* <a href=\"#p3\">Part 3</a>: Use your tokens in a classification model on yelp rating\n",
    "* <a href=\"#p4\">Part 4</a>: Estimate & Interpret a topic model of the Yelp reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "import re\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "yelp = pd.read_json('data/review_sample.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nDuEqIyRc8YKS1q1fX0CZg</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-03-31 16:50:30</td>\n",
       "      <td>0</td>\n",
       "      <td>eZs2tpEJtXPwawvHnHZIgQ</td>\n",
       "      <td>1</td>\n",
       "      <td>BEWARE!!! FAKE, FAKE, FAKE....We also own a sm...</td>\n",
       "      <td>10</td>\n",
       "      <td>n1LM36qNg4rqGXIcvVXv8w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eMYeEapscbKNqUDCx705hg</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-12-16 05:31:03</td>\n",
       "      <td>0</td>\n",
       "      <td>DoQDWJsNbU0KL1O29l_Xug</td>\n",
       "      <td>4</td>\n",
       "      <td>Came here for lunch Togo. Service was quick. S...</td>\n",
       "      <td>0</td>\n",
       "      <td>5CgjjDAic2-FAvCtiHpytA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6Q7-wkCPc1KF75jZLOTcMw</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-06-20 19:14:48</td>\n",
       "      <td>1</td>\n",
       "      <td>DDOdGU7zh56yQHmUnL1idQ</td>\n",
       "      <td>3</td>\n",
       "      <td>I've been to Vegas dozens of times and had nev...</td>\n",
       "      <td>2</td>\n",
       "      <td>BdV-cf3LScmb8kZ7iiBcMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k3zrItO4l9hwfLRwHBDc9w</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-07-13 00:33:45</td>\n",
       "      <td>4</td>\n",
       "      <td>LfTMUWnfGFMOfOIyJcwLVA</td>\n",
       "      <td>1</td>\n",
       "      <td>We went here on a night where they closed off ...</td>\n",
       "      <td>5</td>\n",
       "      <td>cZZnBqh4gAEy4CdNvJailQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6hpfRwGlOzbNv7k5eP9rsQ</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-06-30 02:30:01</td>\n",
       "      <td>0</td>\n",
       "      <td>zJSUdI7bJ8PNJAg4lnl_Gg</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5 to 4 stars\\n\\nNot bad for the price, $12.9...</td>\n",
       "      <td>5</td>\n",
       "      <td>n9QO4ClYAS7h9fpQwa5bhA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  cool                date  funny  \\\n",
       "0  nDuEqIyRc8YKS1q1fX0CZg     1 2015-03-31 16:50:30      0   \n",
       "1  eMYeEapscbKNqUDCx705hg     0 2015-12-16 05:31:03      0   \n",
       "2  6Q7-wkCPc1KF75jZLOTcMw     1 2010-06-20 19:14:48      1   \n",
       "3  k3zrItO4l9hwfLRwHBDc9w     3 2010-07-13 00:33:45      4   \n",
       "4  6hpfRwGlOzbNv7k5eP9rsQ     1 2018-06-30 02:30:01      0   \n",
       "\n",
       "                review_id  stars  \\\n",
       "0  eZs2tpEJtXPwawvHnHZIgQ      1   \n",
       "1  DoQDWJsNbU0KL1O29l_Xug      4   \n",
       "2  DDOdGU7zh56yQHmUnL1idQ      3   \n",
       "3  LfTMUWnfGFMOfOIyJcwLVA      1   \n",
       "4  zJSUdI7bJ8PNJAg4lnl_Gg      4   \n",
       "\n",
       "                                                text  useful  \\\n",
       "0  BEWARE!!! FAKE, FAKE, FAKE....We also own a sm...      10   \n",
       "1  Came here for lunch Togo. Service was quick. S...       0   \n",
       "2  I've been to Vegas dozens of times and had nev...       2   \n",
       "3  We went here on a night where they closed off ...       5   \n",
       "4  3.5 to 4 stars\\n\\nNot bad for the price, $12.9...       5   \n",
       "\n",
       "                  user_id  \n",
       "0  n1LM36qNg4rqGXIcvVXv8w  \n",
       "1  5CgjjDAic2-FAvCtiHpytA  \n",
       "2  BdV-cf3LScmb8kZ7iiBcMA  \n",
       "3  cZZnBqh4gAEy4CdNvJailQ  \n",
       "4  n9QO4ClYAS7h9fpQwa5bhA  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Tokenize Function\n",
    "<a id=\"#p1\"></a>\n",
    "\n",
    "Complete the function `tokenize`. Your function should\n",
    "- accept one document at a time\n",
    "- return a list of tokens\n",
    "\n",
    "You are free to use any method you have learned this week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "\n",
    "    text = nlp(text)\n",
    "    tokens = [token.lemma_ for token in text if (token.is_stop != True) and (token.is_punct != True) and (token.text != \" \")]\n",
    "    return tokens\n",
    "\n",
    "def retoken(text):\n",
    "    \n",
    "    tokens = re.sub(r'[^a-zA-Z ^0-9]', '', text)\n",
    "    tokens = tokens.lower().split()\n",
    "    tokens = str(tokens)\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'Gabe', 'test']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = \"Hello, My name is Gabe and this is a ! test !!!\"\n",
    "tokenize(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "yelp['tokens'] = yelp['text'].apply(tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp['tokens'] = yelp['text'].apply(retoken)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nDuEqIyRc8YKS1q1fX0CZg</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-03-31 16:50:30</td>\n",
       "      <td>0</td>\n",
       "      <td>eZs2tpEJtXPwawvHnHZIgQ</td>\n",
       "      <td>1</td>\n",
       "      <td>BEWARE!!! FAKE, FAKE, FAKE....We also own a sm...</td>\n",
       "      <td>10</td>\n",
       "      <td>n1LM36qNg4rqGXIcvVXv8w</td>\n",
       "      <td>['beware', 'fake', 'fake', 'fakewe', 'also', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eMYeEapscbKNqUDCx705hg</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-12-16 05:31:03</td>\n",
       "      <td>0</td>\n",
       "      <td>DoQDWJsNbU0KL1O29l_Xug</td>\n",
       "      <td>4</td>\n",
       "      <td>Came here for lunch Togo. Service was quick. S...</td>\n",
       "      <td>0</td>\n",
       "      <td>5CgjjDAic2-FAvCtiHpytA</td>\n",
       "      <td>['came', 'here', 'for', 'lunch', 'togo', 'serv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6Q7-wkCPc1KF75jZLOTcMw</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-06-20 19:14:48</td>\n",
       "      <td>1</td>\n",
       "      <td>DDOdGU7zh56yQHmUnL1idQ</td>\n",
       "      <td>3</td>\n",
       "      <td>I've been to Vegas dozens of times and had nev...</td>\n",
       "      <td>2</td>\n",
       "      <td>BdV-cf3LScmb8kZ7iiBcMA</td>\n",
       "      <td>['ive', 'been', 'to', 'vegas', 'dozens', 'of',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k3zrItO4l9hwfLRwHBDc9w</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-07-13 00:33:45</td>\n",
       "      <td>4</td>\n",
       "      <td>LfTMUWnfGFMOfOIyJcwLVA</td>\n",
       "      <td>1</td>\n",
       "      <td>We went here on a night where they closed off ...</td>\n",
       "      <td>5</td>\n",
       "      <td>cZZnBqh4gAEy4CdNvJailQ</td>\n",
       "      <td>['we', 'went', 'here', 'on', 'a', 'night', 'wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6hpfRwGlOzbNv7k5eP9rsQ</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-06-30 02:30:01</td>\n",
       "      <td>0</td>\n",
       "      <td>zJSUdI7bJ8PNJAg4lnl_Gg</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5 to 4 stars\\n\\nNot bad for the price, $12.9...</td>\n",
       "      <td>5</td>\n",
       "      <td>n9QO4ClYAS7h9fpQwa5bhA</td>\n",
       "      <td>['35', 'to', '4', 'starsnot', 'bad', 'for', 't...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  cool                date  funny  \\\n",
       "0  nDuEqIyRc8YKS1q1fX0CZg     1 2015-03-31 16:50:30      0   \n",
       "1  eMYeEapscbKNqUDCx705hg     0 2015-12-16 05:31:03      0   \n",
       "2  6Q7-wkCPc1KF75jZLOTcMw     1 2010-06-20 19:14:48      1   \n",
       "3  k3zrItO4l9hwfLRwHBDc9w     3 2010-07-13 00:33:45      4   \n",
       "4  6hpfRwGlOzbNv7k5eP9rsQ     1 2018-06-30 02:30:01      0   \n",
       "\n",
       "                review_id  stars  \\\n",
       "0  eZs2tpEJtXPwawvHnHZIgQ      1   \n",
       "1  DoQDWJsNbU0KL1O29l_Xug      4   \n",
       "2  DDOdGU7zh56yQHmUnL1idQ      3   \n",
       "3  LfTMUWnfGFMOfOIyJcwLVA      1   \n",
       "4  zJSUdI7bJ8PNJAg4lnl_Gg      4   \n",
       "\n",
       "                                                text  useful  \\\n",
       "0  BEWARE!!! FAKE, FAKE, FAKE....We also own a sm...      10   \n",
       "1  Came here for lunch Togo. Service was quick. S...       0   \n",
       "2  I've been to Vegas dozens of times and had nev...       2   \n",
       "3  We went here on a night where they closed off ...       5   \n",
       "4  3.5 to 4 stars\\n\\nNot bad for the price, $12.9...       5   \n",
       "\n",
       "                  user_id                                             tokens  \n",
       "0  n1LM36qNg4rqGXIcvVXv8w  ['beware', 'fake', 'fake', 'fakewe', 'also', '...  \n",
       "1  5CgjjDAic2-FAvCtiHpytA  ['came', 'here', 'for', 'lunch', 'togo', 'serv...  \n",
       "2  BdV-cf3LScmb8kZ7iiBcMA  ['ive', 'been', 'to', 'vegas', 'dozens', 'of',...  \n",
       "3  cZZnBqh4gAEy4CdNvJailQ  ['we', 'went', 'here', 'on', 'a', 'night', 'wh...  \n",
       "4  n9QO4ClYAS7h9fpQwa5bhA  ['35', 'to', '4', 'starsnot', 'bad', 'for', 't...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Vector Representation\n",
    "<a id=\"#p2\"></a>\n",
    "1. Create a vector representation of the reviews\n",
    "2. Write a fake review and query for the 10 most similiar reviews, print the text of the reviews. Do you notice any patterns?\n",
    "    - Given the size of the dataset, it will probably be best to use a `NearestNeighbors` model for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer()\n",
    "vect.fit(yelp['tokens'])\n",
    "dtm = vect.transform(yelp['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_df = pd.DataFrame(dtm.todense(), columns = vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>001695do</th>\n",
       "      <th>001695howard</th>\n",
       "      <th>007</th>\n",
       "      <th>011802</th>\n",
       "      <th>0227</th>\n",
       "      <th>025</th>\n",
       "      <th>035lbs</th>\n",
       "      <th>04</th>\n",
       "      <th>04162016</th>\n",
       "      <th>05</th>\n",
       "      <th>...</th>\n",
       "      <th>zuma</th>\n",
       "      <th>zumanity</th>\n",
       "      <th>zumba</th>\n",
       "      <th>zuni</th>\n",
       "      <th>zupas</th>\n",
       "      <th>zuzana</th>\n",
       "      <th>zuzu</th>\n",
       "      <th>zyrtec</th>\n",
       "      <th>zzaplon</th>\n",
       "      <th>zzzzzzzzzmy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38008 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   001695do  001695howard  007  011802  0227  025  035lbs  04  04162016  05  \\\n",
       "0         0             0    0       0     0    0       0   0         0   0   \n",
       "1         0             0    0       0     0    0       0   0         0   0   \n",
       "2         0             0    0       0     0    0       0   0         0   0   \n",
       "3         0             0    0       0     0    0       0   0         0   0   \n",
       "4         0             0    0       0     0    0       0   0         0   0   \n",
       "\n",
       "   ...  zuma  zumanity  zumba  zuni  zupas  zuzana  zuzu  zyrtec  zzaplon  \\\n",
       "0  ...     0         0      0     0      0       0     0       0        0   \n",
       "1  ...     0         0      0     0      0       0     0       0        0   \n",
       "2  ...     0         0      0     0      0       0     0       0        0   \n",
       "3  ...     0         0      0     0      0       0     0       0        0   \n",
       "4  ...     0         0      0     0      0       0     0       0        0   \n",
       "\n",
       "   zzzzzzzzzmy  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "\n",
       "[5 rows x 38008 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=tokenize, min_df=0.025, max_df=.98, ngram_range=(1,2))\n",
    "dtm = tfidf.fit_transform(yelp['tokens'])\n",
    "dtm = pd.DataFrame(dtm.todense(), columns = tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
       "                 metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                 radius=1.0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = NearestNeighbors(n_neighbors = 5, algorithm = 'kd_tree')\n",
    "nn.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.        , 0.86999953, 0.94229328, 0.9456555 , 0.95554834]]),\n",
       " array([[  10, 5531, 9086, 8348, 5741]], dtype=int64))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.kneighbors([dtm.iloc[10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['pizza', 'is', 'a', 'staple', 'for', 'me', 'i', 'love', 'everything', 'about', 'crunch', 'crust', 'a', 'nice', 'rich', 'tomato', 'sauce', 'and', 'a', 'thick', 'layer', 'of', 'melted', 'cheese', 'i', 'have', 'never', 'tried', 'chicago', 'style', 'pizza', 'before', 'and', 'when', 'we', 'had', 'to', '\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp['tokens'][5531][:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['this', 'pizza', 'is', 'so', 'good', 'i', 'went', 'here', 'with', 'my', 'mom', 'after', 'work', 'and', 'the', 'environment', 'was', 'really', 'chill', 'and', 'relaxing', 'and', 'the', 'servers', 'were', 'really', 'nice', 'too', 'their', 'pizzas', 'are', 'innovative', 'without', 'being', 'too', 'muc\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp['tokens'][5741][:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = [\"The pizza was ok, me and my mom had to wait for about 20 min which was fine but i would have much prefered to be seated earlier\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1., 1., 1., 1., 1.]]),\n",
       " array([[4839, 6204, 6311, 3469, 9889]], dtype=int64))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = tfidf.transform(fake)\n",
    "nn.kneighbors(new.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The pizza was ok, me and my mom had to wait for about 20 min which was fine but i would have much prefered to be seated earlier']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['bon', 'massage', 'spa', 'propre', 'organis', 'manque', 'juste', 'le', 'stationnement', 'prix', 'abordable', 'en', 'promotion', 'personnels', 'respectueux']\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp['tokens'][9889][:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Classification\n",
    "<a id=\"#p3\"></a>\n",
    "Your goal in this section will be to predict `stars` from the review dataset. \n",
    "\n",
    "1. Create a piepline object with a sklearn `CountVectorizer` or `TfidfVector` and any sklearn classifier. Use that pipeline to estimate a model to predict `stars`. Use the Pipeline to predict a star rating for your fake review from Part 2. \n",
    "2. Tune the entire pipeline with a GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(stop_words = 'english')\n",
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('vect',vect),('rf',rf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'vect__max_df': ( 0.8, 1.0),        \n",
    "    'vect__min_df': (.02, .05),          \n",
    "    'vect__max_features': (1000,5000),\n",
    "    'rf__n_estimators':(5, 100,),\n",
    "    'rf__max_depth':(15,30)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 32 candidates, totalling 192 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   16.7s\n",
      "[Parallel(n_jobs=-1)]: Done 192 out of 192 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=6, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words...\n",
       "                                                               n_estimators='warn',\n",
       "                                                               n_jobs=None,\n",
       "                                                               oob_score=False,\n",
       "                                                               random_state=None,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'rf__max_depth': (15, 30),\n",
       "                         'rf__n_estimators': (5, 100),\n",
       "                         'vect__max_df': (0.8, 1.0),\n",
       "                         'vect__max_features': (1000, 5000),\n",
       "                         'vect__min_df': (0.02, 0.05)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=True)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = GridSearchCV(pipe,parameters,cv = 6, n_jobs = -1, verbose = True)\n",
    "gs.fit(yelp['tokens'], yelp['stars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5643"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = gs.predict(yelp['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pd.DataFrame({'desc': yelp['text'], 'rate':pred})\n",
    "p['rate'] = p['rate'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BEWARE!!! FAKE, FAKE, FAKE....We also own a sm...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Came here for lunch Togo. Service was quick. S...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I've been to Vegas dozens of times and had nev...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We went here on a night where they closed off ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.5 to 4 stars\\n\\nNot bad for the price, $12.9...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tasty, fast casual Latin street food.  The men...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>This show is absolutely amazing!! What an incr...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Came for the Pho and really enjoyed it!  We go...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Absolutely the most Unique experience in a nai...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Wow. I walked in and sat at the bar for 10 min...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                desc  rate\n",
       "0  BEWARE!!! FAKE, FAKE, FAKE....We also own a sm...     1\n",
       "1  Came here for lunch Togo. Service was quick. S...     4\n",
       "2  I've been to Vegas dozens of times and had nev...     3\n",
       "3  We went here on a night where they closed off ...     5\n",
       "4  3.5 to 4 stars\\n\\nNot bad for the price, $12.9...     4\n",
       "5  Tasty, fast casual Latin street food.  The men...     4\n",
       "6  This show is absolutely amazing!! What an incr...     5\n",
       "7  Came for the Pho and really enjoyed it!  We go...     4\n",
       "8  Absolutely the most Unique experience in a nai...     5\n",
       "9  Wow. I walked in and sat at the bar for 10 min...     1"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nDuEqIyRc8YKS1q1fX0CZg</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-03-31 16:50:30</td>\n",
       "      <td>0</td>\n",
       "      <td>eZs2tpEJtXPwawvHnHZIgQ</td>\n",
       "      <td>1</td>\n",
       "      <td>BEWARE!!! FAKE, FAKE, FAKE....We also own a sm...</td>\n",
       "      <td>10</td>\n",
       "      <td>n1LM36qNg4rqGXIcvVXv8w</td>\n",
       "      <td>['beware', 'fake', 'fake', 'fakewe', 'also', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eMYeEapscbKNqUDCx705hg</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-12-16 05:31:03</td>\n",
       "      <td>0</td>\n",
       "      <td>DoQDWJsNbU0KL1O29l_Xug</td>\n",
       "      <td>4</td>\n",
       "      <td>Came here for lunch Togo. Service was quick. S...</td>\n",
       "      <td>0</td>\n",
       "      <td>5CgjjDAic2-FAvCtiHpytA</td>\n",
       "      <td>['came', 'here', 'for', 'lunch', 'togo', 'serv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6Q7-wkCPc1KF75jZLOTcMw</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-06-20 19:14:48</td>\n",
       "      <td>1</td>\n",
       "      <td>DDOdGU7zh56yQHmUnL1idQ</td>\n",
       "      <td>3</td>\n",
       "      <td>I've been to Vegas dozens of times and had nev...</td>\n",
       "      <td>2</td>\n",
       "      <td>BdV-cf3LScmb8kZ7iiBcMA</td>\n",
       "      <td>['ive', 'been', 'to', 'vegas', 'dozens', 'of',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k3zrItO4l9hwfLRwHBDc9w</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-07-13 00:33:45</td>\n",
       "      <td>4</td>\n",
       "      <td>LfTMUWnfGFMOfOIyJcwLVA</td>\n",
       "      <td>1</td>\n",
       "      <td>We went here on a night where they closed off ...</td>\n",
       "      <td>5</td>\n",
       "      <td>cZZnBqh4gAEy4CdNvJailQ</td>\n",
       "      <td>['we', 'went', 'here', 'on', 'a', 'night', 'wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6hpfRwGlOzbNv7k5eP9rsQ</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-06-30 02:30:01</td>\n",
       "      <td>0</td>\n",
       "      <td>zJSUdI7bJ8PNJAg4lnl_Gg</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5 to 4 stars\\n\\nNot bad for the price, $12.9...</td>\n",
       "      <td>5</td>\n",
       "      <td>n9QO4ClYAS7h9fpQwa5bhA</td>\n",
       "      <td>['35', 'to', '4', 'starsnot', 'bad', 'for', 't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Db3CfZWrtG33UZSs8Tdlsg</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-10-23 22:43:56</td>\n",
       "      <td>1</td>\n",
       "      <td>nXYV_0joQEMXYAfNyOPsRw</td>\n",
       "      <td>4</td>\n",
       "      <td>Tasty, fast casual Latin street food.  The men...</td>\n",
       "      <td>1</td>\n",
       "      <td>Gjz2PCbLZ6midk1n_0LaUg</td>\n",
       "      <td>['tasty', 'fast', 'casual', 'latin', 'street',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gJhMeq2nVH27tz8LqbD3eQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-05-20 19:09:43</td>\n",
       "      <td>0</td>\n",
       "      <td>ZA7SRi6fTRWwpo-B9O72qQ</td>\n",
       "      <td>5</td>\n",
       "      <td>This show is absolutely amazing!! What an incr...</td>\n",
       "      <td>0</td>\n",
       "      <td>BeKPVuqX-2at4izqVwUFEg</td>\n",
       "      <td>['this', 'show', 'is', 'absolutely', 'amazing'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Yt5gK4E9NqVa14WNiQdBlQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-07-12 01:19:53</td>\n",
       "      <td>0</td>\n",
       "      <td>4_GnHPkyTirzK6onIKO4jw</td>\n",
       "      <td>4</td>\n",
       "      <td>Came for the Pho and really enjoyed it!  We go...</td>\n",
       "      <td>0</td>\n",
       "      <td>PuXpIJzTBQejeBZh9hwynQ</td>\n",
       "      <td>['came', 'for', 'the', 'pho', 'and', 'really',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>c7WsC8SbUcLyZkREzx9dGA</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-09-27 22:10:26</td>\n",
       "      <td>0</td>\n",
       "      <td>XGGHc7pYgOm5s6SWr8NMXA</td>\n",
       "      <td>5</td>\n",
       "      <td>Absolutely the most Unique experience in a nai...</td>\n",
       "      <td>0</td>\n",
       "      <td>NVVknS1I51z8wY5NNrJ6vQ</td>\n",
       "      <td>['absolutely', 'the', 'most', 'unique', 'exper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NSifXpsCRvnsBRqrHF9CJA</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-25 08:43:15</td>\n",
       "      <td>0</td>\n",
       "      <td>--e66tyhwCE6eoRmcK2w8g</td>\n",
       "      <td>1</td>\n",
       "      <td>Wow. I walked in and sat at the bar for 10 min...</td>\n",
       "      <td>2</td>\n",
       "      <td>J7MsJKJDSA5OGo2-Hn7MbA</td>\n",
       "      <td>['wow', 'i', 'walked', 'in', 'and', 'sat', 'at...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  cool                date  funny  \\\n",
       "0  nDuEqIyRc8YKS1q1fX0CZg     1 2015-03-31 16:50:30      0   \n",
       "1  eMYeEapscbKNqUDCx705hg     0 2015-12-16 05:31:03      0   \n",
       "2  6Q7-wkCPc1KF75jZLOTcMw     1 2010-06-20 19:14:48      1   \n",
       "3  k3zrItO4l9hwfLRwHBDc9w     3 2010-07-13 00:33:45      4   \n",
       "4  6hpfRwGlOzbNv7k5eP9rsQ     1 2018-06-30 02:30:01      0   \n",
       "5  Db3CfZWrtG33UZSs8Tdlsg     1 2016-10-23 22:43:56      1   \n",
       "6  gJhMeq2nVH27tz8LqbD3eQ     0 2013-05-20 19:09:43      0   \n",
       "7  Yt5gK4E9NqVa14WNiQdBlQ     0 2018-07-12 01:19:53      0   \n",
       "8  c7WsC8SbUcLyZkREzx9dGA     1 2017-09-27 22:10:26      0   \n",
       "9  NSifXpsCRvnsBRqrHF9CJA     0 2015-01-25 08:43:15      0   \n",
       "\n",
       "                review_id  stars  \\\n",
       "0  eZs2tpEJtXPwawvHnHZIgQ      1   \n",
       "1  DoQDWJsNbU0KL1O29l_Xug      4   \n",
       "2  DDOdGU7zh56yQHmUnL1idQ      3   \n",
       "3  LfTMUWnfGFMOfOIyJcwLVA      1   \n",
       "4  zJSUdI7bJ8PNJAg4lnl_Gg      4   \n",
       "5  nXYV_0joQEMXYAfNyOPsRw      4   \n",
       "6  ZA7SRi6fTRWwpo-B9O72qQ      5   \n",
       "7  4_GnHPkyTirzK6onIKO4jw      4   \n",
       "8  XGGHc7pYgOm5s6SWr8NMXA      5   \n",
       "9  --e66tyhwCE6eoRmcK2w8g      1   \n",
       "\n",
       "                                                text  useful  \\\n",
       "0  BEWARE!!! FAKE, FAKE, FAKE....We also own a sm...      10   \n",
       "1  Came here for lunch Togo. Service was quick. S...       0   \n",
       "2  I've been to Vegas dozens of times and had nev...       2   \n",
       "3  We went here on a night where they closed off ...       5   \n",
       "4  3.5 to 4 stars\\n\\nNot bad for the price, $12.9...       5   \n",
       "5  Tasty, fast casual Latin street food.  The men...       1   \n",
       "6  This show is absolutely amazing!! What an incr...       0   \n",
       "7  Came for the Pho and really enjoyed it!  We go...       0   \n",
       "8  Absolutely the most Unique experience in a nai...       0   \n",
       "9  Wow. I walked in and sat at the bar for 10 min...       2   \n",
       "\n",
       "                  user_id                                             tokens  \n",
       "0  n1LM36qNg4rqGXIcvVXv8w  ['beware', 'fake', 'fake', 'fakewe', 'also', '...  \n",
       "1  5CgjjDAic2-FAvCtiHpytA  ['came', 'here', 'for', 'lunch', 'togo', 'serv...  \n",
       "2  BdV-cf3LScmb8kZ7iiBcMA  ['ive', 'been', 'to', 'vegas', 'dozens', 'of',...  \n",
       "3  cZZnBqh4gAEy4CdNvJailQ  ['we', 'went', 'here', 'on', 'a', 'night', 'wh...  \n",
       "4  n9QO4ClYAS7h9fpQwa5bhA  ['35', 'to', '4', 'starsnot', 'bad', 'for', 't...  \n",
       "5  Gjz2PCbLZ6midk1n_0LaUg  ['tasty', 'fast', 'casual', 'latin', 'street',...  \n",
       "6  BeKPVuqX-2at4izqVwUFEg  ['this', 'show', 'is', 'absolutely', 'amazing'...  \n",
       "7  PuXpIJzTBQejeBZh9hwynQ  ['came', 'for', 'the', 'pho', 'and', 'really',...  \n",
       "8  NVVknS1I51z8wY5NNrJ6vQ  ['absolutely', 'the', 'most', 'unique', 'exper...  \n",
       "9  J7MsJKJDSA5OGo2-Hn7MbA  ['wow', 'i', 'walked', 'in', 'and', 'sat', 'at...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Topic Modeling\n",
    "\n",
    "Let's find out what those yelp reviews are saying! :D\n",
    "\n",
    "1. Estimate a LDA topic model of the review text\n",
    "    - Keep the `iterations` parameter at or below 5 to reduce run time\n",
    "    - The `workers` parameter should match the number of physical cores on your machine.\n",
    "2. Create 1-2 visualizations of the results\n",
    "    - You can use the most important 3 words of a topic in relevant visualizations. Refer to yesterday's notebook to extract. \n",
    "3. In markdown, write 1-2 paragraphs of analysis on the results of your topic model\n",
    "\n",
    "__*Note*__: You can pass the DataFrame column of text reviews to gensim. You do not have to use a generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "yelp['tokens'] = yelp['text'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "from gensim.models import LdaMulticore\n",
    "from gensim.corpora import Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn the vocubalary of the yelp data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = Dictionary(yelp['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word.filter_extremes(no_below=10, no_above=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a bag of words representation of the entire corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "corpus = [id2word.doc2bow(text) for text in yelp['tokens']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your LDA model should be ready for estimation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "lda = LdaMulticore(corpus=corpus,\n",
    "                   id2word=id2word,\n",
    "                   iterations=5,\n",
    "                   workers=8,\n",
    "                   num_topics = 20 # You can change this parameter\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 1-2 visualizations of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.021*\"good\" + 0.021*\"\\n\\n\" + 0.013*\"place\" + 0.010*\"come\" + 0.010*\"time\" + 0.009*\"like\" + 0.009*\"food\" + 0.009*\"service\" + 0.009*\"order\" + 0.007*\"love\"'),\n",
       " (1,\n",
       "  '0.020*\"\\n\\n\" + 0.012*\"great\" + 0.012*\"place\" + 0.011*\"go\" + 0.010*\"food\" + 0.009*\"order\" + 0.009*\"good\" + 0.008*\"service\" + 0.008*\"come\" + 0.008*\"get\"'),\n",
       " (2,\n",
       "  '0.020*\"\\n\\n\" + 0.013*\"place\" + 0.011*\"food\" + 0.011*\"good\" + 0.010*\"like\" + 0.010*\"time\" + 0.010*\"great\" + 0.010*\"order\" + 0.010*\"service\" + 0.009*\"$\"'),\n",
       " (3,\n",
       "  '0.023*\"\\n\\n\" + 0.013*\"good\" + 0.011*\"place\" + 0.010*\"food\" + 0.009*\"order\" + 0.008*\"like\" + 0.008*\"time\" + 0.007*\"go\" + 0.007*\"great\" + 0.007*\"come\"'),\n",
       " (4,\n",
       "  '0.016*\"\\n\\n\" + 0.015*\"come\" + 0.015*\"place\" + 0.014*\"time\" + 0.012*\"\\n\" + 0.011*\"food\" + 0.011*\"good\" + 0.010*\"great\" + 0.008*\"get\" + 0.008*\"service\"'),\n",
       " (5,\n",
       "  '0.016*\"\\n\\n\" + 0.014*\"place\" + 0.013*\"great\" + 0.012*\"food\" + 0.011*\"good\" + 0.009*\"order\" + 0.009*\"like\" + 0.008*\"time\" + 0.008*\"go\" + 0.007*\"service\"'),\n",
       " (6,\n",
       "  '0.024*\"\\n\\n\" + 0.014*\"good\" + 0.011*\"food\" + 0.011*\"time\" + 0.010*\"place\" + 0.010*\"come\" + 0.009*\"\\n\" + 0.008*\"order\" + 0.007*\"service\" + 0.007*\"go\"'),\n",
       " (7,\n",
       "  '0.020*\"good\" + 0.019*\"\\n\\n\" + 0.015*\"food\" + 0.014*\"great\" + 0.010*\"service\" + 0.009*\"time\" + 0.008*\"like\" + 0.008*\"come\" + 0.008*\"\\n\" + 0.008*\"place\"'),\n",
       " (8,\n",
       "  '0.023*\"\\n\\n\" + 0.016*\"place\" + 0.013*\"food\" + 0.012*\"good\" + 0.009*\"time\" + 0.008*\"order\" + 0.007*\"like\" + 0.007*\"great\" + 0.007*\"try\" + 0.007*\"go\"'),\n",
       " (9,\n",
       "  '0.017*\"\\n\\n\" + 0.017*\"good\" + 0.013*\"place\" + 0.013*\"food\" + 0.011*\"service\" + 0.011*\"\\n\" + 0.010*\"time\" + 0.009*\"like\" + 0.009*\"come\" + 0.008*\"great\"'),\n",
       " (10,\n",
       "  '0.016*\"\\n\\n\" + 0.014*\"good\" + 0.012*\"place\" + 0.012*\"come\" + 0.012*\"order\" + 0.009*\"time\" + 0.009*\"great\" + 0.008*\"like\" + 0.008*\"service\" + 0.007*\"food\"'),\n",
       " (11,\n",
       "  '0.017*\"\\n\\n\" + 0.014*\"food\" + 0.011*\"great\" + 0.011*\"good\" + 0.009*\"place\" + 0.008*\"like\" + 0.007*\"go\" + 0.007*\"service\" + 0.007*\"time\" + 0.007*\"come\"'),\n",
       " (12,\n",
       "  '0.019*\"\\n\\n\" + 0.012*\"place\" + 0.012*\"good\" + 0.011*\"time\" + 0.009*\"like\" + 0.009*\"great\" + 0.009*\"get\" + 0.009*\"food\" + 0.008*\"come\" + 0.007*\"order\"'),\n",
       " (13,\n",
       "  '0.017*\"\\n\\n\" + 0.016*\"good\" + 0.013*\"place\" + 0.012*\"come\" + 0.010*\"like\" + 0.010*\"food\" + 0.010*\"time\" + 0.009*\"try\" + 0.008*\"$\" + 0.008*\"get\"'),\n",
       " (14,\n",
       "  '0.021*\"\\n\\n\" + 0.017*\"good\" + 0.015*\"place\" + 0.013*\"food\" + 0.011*\"great\" + 0.011*\"\\n\" + 0.010*\"like\" + 0.010*\"time\" + 0.008*\"service\" + 0.007*\"order\"'),\n",
       " (15,\n",
       "  '0.021*\"\\n\\n\" + 0.013*\"good\" + 0.012*\"place\" + 0.011*\"like\" + 0.011*\"time\" + 0.011*\"order\" + 0.008*\"service\" + 0.008*\"food\" + 0.008*\"get\" + 0.008*\"come\"'),\n",
       " (16,\n",
       "  '0.020*\"\\n\\n\" + 0.013*\"good\" + 0.010*\"great\" + 0.010*\"food\" + 0.009*\"service\" + 0.009*\"place\" + 0.009*\"\\n\" + 0.008*\"time\" + 0.007*\"order\" + 0.007*\"like\"'),\n",
       " (17,\n",
       "  '0.017*\"\\n\\n\" + 0.017*\"good\" + 0.012*\"food\" + 0.009*\"great\" + 0.009*\"place\" + 0.009*\"time\" + 0.009*\"service\" + 0.008*\"come\" + 0.008*\"go\" + 0.008*\"\\n\"'),\n",
       " (18,\n",
       "  '0.021*\"\\n\\n\" + 0.012*\"good\" + 0.012*\"place\" + 0.011*\"food\" + 0.009*\"great\" + 0.008*\"like\" + 0.008*\"time\" + 0.008*\"come\" + 0.008*\"order\" + 0.007*\"service\"'),\n",
       " (19,\n",
       "  '0.018*\"good\" + 0.013*\"food\" + 0.012*\"time\" + 0.011*\"great\" + 0.010*\"\\n\\n\" + 0.010*\"come\" + 0.010*\"\\n\" + 0.010*\"go\" + 0.009*\"place\" + 0.008*\"service\"')]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good \n",
      "\n",
      " place come time\n",
      "\n",
      "\n",
      " great place go food\n",
      "\n",
      "\n",
      " place food good like\n",
      "\n",
      "\n",
      " good place food order\n",
      "\n",
      "\n",
      " come place time \n",
      "\n",
      "\n",
      "\n",
      " place great food good\n",
      "\n",
      "\n",
      " good food time place\n",
      "good \n",
      "\n",
      " food great service\n",
      "\n",
      "\n",
      " place food good time\n",
      "\n",
      "\n",
      " good place food service\n",
      "\n",
      "\n",
      " good place come order\n",
      "\n",
      "\n",
      " food great good place\n",
      "\n",
      "\n",
      " place good time like\n",
      "\n",
      "\n",
      " good place come like\n",
      "\n",
      "\n",
      " good place food great\n",
      "\n",
      "\n",
      " good place like time\n",
      "\n",
      "\n",
      " good great food service\n",
      "\n",
      "\n",
      " good food great place\n",
      "\n",
      "\n",
      " good place food great\n",
      "good food time great \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words = [re.findall(r'\"([^\"]*)\"',t[1]) for t in lda.print_topics()]\n",
    "topics = [' '.join(t[0:5]) for t in words]\n",
    "for t in topics: \n",
    "    print(t)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results from the topic model, we can assume that the overall topic is a resturaunt. That part is obvious since all the reviews were from a resturaunt, but we can also conclude that most of the people going to the resturaunt enjoyed the food and the service there. In all honesty im not sure how accurate these topics are becasue of multiple complications that came up when creating the model, but im out of time and am not going to mess with it any further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stretch Goals\n",
    "\n",
    "Complete one of more of these to push your score towards a three: \n",
    "* Incorporate named entity recognition into your analysis\n",
    "* Compare vectorization methods in the classification section\n",
    "* Analyze more (or all) of the yelp dataset - this one is v. hard. \n",
    "* Use a generator object on the reviews file - this would help you with the analyzing the whole dataset.\n",
    "* Incorporate any of the other yelp dataset entities in your analysis (business, users, etc.)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "u4-s1-nlp"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "0.14.5"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
